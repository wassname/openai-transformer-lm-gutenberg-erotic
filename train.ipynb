{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-04T05:19:26.254969Z",
     "start_time": "2018-11-04T05:19:25.883714Z"
    }
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "%reload_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-04T07:26:02.575703Z",
     "start_time": "2018-11-04T07:26:02.531435Z"
    }
   },
   "outputs": [],
   "source": [
    "import argparse\n",
    "import os\n",
    "import random\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.utils import shuffle\n",
    "\n",
    "from analysis import rocstories as rocstories_analysis\n",
    "from datasets import rocstories\n",
    "from model_pytorch import DoubleHeadModel, load_openai_pretrained_model\n",
    "from opt import OpenAIAdam\n",
    "from text_utils import TextEncoder\n",
    "from utils import (encode_dataset, iter_data,\n",
    "                   ResultLogger, make_path, np_softmax)\n",
    "from loss import LMLossCompute"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Helpers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-04T05:19:28.072871Z",
     "start_time": "2018-11-04T05:19:28.014007Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def transform_roc(X1, X2, X3):\n",
    "    \"\"\"pad and crop sequences\"\"\"\n",
    "    n_batch = len(X1)\n",
    "    xmb = np.zeros((n_batch, 2, n_ctx, 2), dtype=np.int32)\n",
    "    mmb = np.zeros((n_batch, 2, n_ctx), dtype=np.float32)\n",
    "    start = encoder['_start_']\n",
    "    delimiter = encoder['_delimiter_']\n",
    "    for i, (x1, x2, x3), in enumerate(zip(X1, X2, X3)):\n",
    "        x12 = [start] + x1[:max_len] + [delimiter] + x2[:max_len] + [clf_token]\n",
    "        x13 = [start] + x1[:max_len] + [delimiter] + x3[:max_len] + [clf_token]\n",
    "        l12 = len(x12)\n",
    "        l13 = len(x13)\n",
    "        xmb[i, 0, :l12, 0] = x12\n",
    "        xmb[i, 1, :l13, 0] = x13\n",
    "        mmb[i, 0, :l12] = 1\n",
    "        mmb[i, 1, :l13] = 1\n",
    "    # Position information that is added to the input embeddings in the TransformerModel\n",
    "    xmb[:, :, :, 1] = np.arange(n_vocab + n_special, n_vocab + n_special + n_ctx)\n",
    "    return xmb, mmb\n",
    "\n",
    "\n",
    "# def iter_apply(Xs, Ms, Ys):\n",
    "#     # fns = [lambda x: np.concatenate(x, 0), lambda x: float(np.sum(x))]\n",
    "#     logits = []\n",
    "#     cost = 0\n",
    "#     with torch.no_grad():\n",
    "#         dh_model.eval()\n",
    "#         for xmb, mmb, ymb in iter_data(Xs, Ms, Ys, n_batch=n_batch_train, truncate=False, verbose=True):\n",
    "#             n = len(xmb)\n",
    "#             XMB = torch.tensor(xmb, dtype=torch.long).to(device)\n",
    "#             YMB = torch.tensor(ymb, dtype=torch.long).to(device)\n",
    "#             MMB = torch.tensor(mmb).to(device)\n",
    "#             lm_logits, clf_logits = dh_model(XMB)\n",
    "#             clf_logits *= n\n",
    "#             clf_losses = compute_loss_fct(XMB, YMB, MMB, clf_logits, only_return_losses=True)\n",
    "#             clf_losses *= n\n",
    "#             logits.append(clf_logits.to(\"cpu\").numpy())\n",
    "#             cost += clf_losses.sum().item()\n",
    "#         logits = np.concatenate(logits, 0)\n",
    "#     return logits, cost\n",
    "\n",
    "\n",
    "def log(save_dir, desc):\n",
    "    global best_score\n",
    "    print(\"Logging\")\n",
    "#     tr_logits, tr_cost = iter_apply(trX[:n_valid], trM[:n_valid], trY[:n_valid])\n",
    "#     va_logits, va_cost = iter_apply(vaX, vaM, vaY)\n",
    "#     tr_cost = tr_cost / len(trY[:n_valid])\n",
    "#     va_cost = va_cost / n_valid\n",
    "#     tr_acc = accuracy_score(trY[:n_valid], np.argmax(tr_logits, 1)) * 100.\n",
    "#     va_acc = accuracy_score(vaY, np.argmax(va_logits, 1)) * 100.\n",
    "    logger.log(n_epochs=n_epochs, n_updates=n_updates)#, tr_cost=tr_cost, va_cost=va_cost, tr_acc=tr_acc, va_acc=va_acc)\n",
    "    print('%d %d %.3f %.3f %.2f %.2f' % (n_epochs, n_updates))#, tr_cost, va_cost, tr_acc, va_acc))\n",
    "#     if submit:\n",
    "#         score = va_acc\n",
    "#         if score > best_score:\n",
    "#             best_score = score\n",
    "#             path = os.path.join(save_dir, desc, 'best_params')\n",
    "#             torch.save(dh_model.state_dict(), make_path(path))\n",
    "\n",
    "def run_epoch():\n",
    "    for xmb, mmb, ymb in iter_data(*shuffle(trX, trM, trYt, random_state=np.random),\n",
    "                                   n_batch=n_batch_train, truncate=True, verbose=True):\n",
    "        global n_updates\n",
    "        dh_model.train()\n",
    "        XMB = torch.tensor(xmb, dtype=torch.long).to(device)\n",
    "        YMB = torch.tensor(ymb, dtype=torch.long).to(device)\n",
    "        MMB = torch.tensor(mmb).to(device)\n",
    "        lm_logits, _ = dh_model(XMB)\n",
    "        compute_loss_fct(XMB, YMB, MMB, lm_logits)\n",
    "        n_updates += 1\n",
    "        if n_updates in [1000, 2000, 4000, 8000, 16000, 32000] and n_epochs == 0:\n",
    "            log(save_dir, desc)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-04T05:19:28.114577Z",
     "start_time": "2018-11-04T05:19:28.076114Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "argmax = lambda x: np.argmax(x, 1)\n",
    "\n",
    "pred_fns = {\n",
    "    'rocstories': argmax,\n",
    "}\n",
    "\n",
    "filenames = {\n",
    "    'rocstories': 'ROCStories.tsv',\n",
    "}\n",
    "\n",
    "label_decoders = {\n",
    "    'rocstories': None,\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-04T07:34:59.634273Z",
     "start_time": "2018-11-04T07:34:59.573211Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Namespace(afn='gelu', analysis=False, attn_pdrop=0.1, b1=0.9, b2=0.999, bpe_path='model/vocab_40000.bpe', clf_pdrop=0.1, data_dir='data/', dataset='data/corpus/erotic_gutenberg.csv', desc=None, e=1e-08, embd_pdrop=0.1, encoder_path='model/encoder_bpe_40000.json', l2=0.01, lm_coef=0.5, log_dir='log/', lr=6.25e-05, lr_schedule='warmup_linear', lr_warmup=0.002, max_grad_norm=1, n_batch=2, n_ctx=512, n_embd=768, n_head=12, n_iter=3, n_layer=12, n_transfer=12, n_valid=374, opt='adam', resid_pdrop=0.1, save_dir='save/', seed=42, submission_dir='submission/', submit=True, vector_l2=False)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "parser = argparse.ArgumentParser()\n",
    "parser.add_argument('--desc', type=str, help=\"Description\")\n",
    "parser.add_argument('--dataset', type=str)\n",
    "parser.add_argument('--log_dir', type=str, default='log/')\n",
    "parser.add_argument('--save_dir', type=str, default='save/')\n",
    "parser.add_argument('--data_dir', type=str, default='data/')\n",
    "parser.add_argument('--submission_dir', type=str, default='submission/')\n",
    "parser.add_argument('--submit', action='store_true')\n",
    "parser.add_argument('--analysis', action='store_true')\n",
    "parser.add_argument('--seed', type=int, default=42)\n",
    "parser.add_argument('--n_iter', type=int, default=3)\n",
    "parser.add_argument('--n_batch', type=int, default=8)\n",
    "parser.add_argument('--max_grad_norm', type=int, default=1)\n",
    "parser.add_argument('--lr', type=float, default=6.25e-5)\n",
    "parser.add_argument('--lr_warmup', type=float, default=0.002)\n",
    "parser.add_argument('--n_ctx', type=int, default=512)\n",
    "parser.add_argument('--n_embd', type=int, default=768)\n",
    "parser.add_argument('--n_head', type=int, default=12)\n",
    "parser.add_argument('--n_layer', type=int, default=12)\n",
    "parser.add_argument('--embd_pdrop', type=float, default=0.1)\n",
    "parser.add_argument('--attn_pdrop', type=float, default=0.1)\n",
    "parser.add_argument('--resid_pdrop', type=float, default=0.1)\n",
    "parser.add_argument('--clf_pdrop', type=float, default=0.1)\n",
    "parser.add_argument('--l2', type=float, default=0.01)\n",
    "parser.add_argument('--vector_l2', action='store_true')\n",
    "parser.add_argument('--opt', type=str, default='adam')\n",
    "parser.add_argument('--afn', type=str, default='gelu')\n",
    "parser.add_argument('--lr_schedule', type=str, default='warmup_linear')\n",
    "parser.add_argument('--encoder_path', type=str, default='model/encoder_bpe_40000.json')\n",
    "parser.add_argument('--bpe_path', type=str, default='model/vocab_40000.bpe')\n",
    "parser.add_argument('--n_transfer', type=int, default=12)\n",
    "parser.add_argument('--lm_coef', type=float, default=0.5)\n",
    "parser.add_argument('--b1', type=float, default=0.9)\n",
    "parser.add_argument('--b2', type=float, default=0.999)\n",
    "parser.add_argument('--e', type=float, default=1e-8)\n",
    "parser.add_argument('--n_valid', type=int, default=374)\n",
    "\n",
    "\n",
    "args = parser.parse_args('''\n",
    "--dataset data/corpus/erotic_gutenberg.csv \n",
    "--n_batch 2 \n",
    "--submit \n",
    "--n_iter 15\n",
    "'''.replace('\\n','').split(' '))\n",
    "print(args)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Init"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-04T07:35:01.392474Z",
     "start_time": "2018-11-04T07:35:01.318042Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "device cuda n_gpu 1\n"
     ]
    }
   ],
   "source": [
    "random.seed(args.seed)\n",
    "np.random.seed(args.seed)\n",
    "torch.manual_seed(args.seed)\n",
    "torch.cuda.manual_seed_all(args.seed)\n",
    "\n",
    "# Constants\n",
    "submit = args.submit\n",
    "dataset = args.dataset\n",
    "n_ctx = args.n_ctx\n",
    "save_dir = args.save_dir\n",
    "desc = args.desc\n",
    "data_dir = args.data_dir\n",
    "log_dir = args.log_dir\n",
    "submission_dir = args.submission_dir\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "n_gpu = torch.cuda.device_count()\n",
    "print(\"device\", device, \"n_gpu\", n_gpu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-04T07:35:06.432028Z",
     "start_time": "2018-11-04T07:35:05.791318Z"
    }
   },
   "outputs": [],
   "source": [
    "logger = ResultLogger(\n",
    "    path=os.path.join(log_dir, '{}.jsonl'.format(desc)), **args.__dict__)\n",
    "\n",
    "# bpe tokenizer BYTE PAIR ENCODING https://en.wikipedia.org/wiki/Byte_pair_encoding\n",
    "# this is compression where we replace frequent pairs with unused byte codes\n",
    "text_encoder = TextEncoder(args.encoder_path, args.bpe_path)\n",
    "encoder = text_encoder.encoder\n",
    "n_vocab = len(text_encoder.encoder)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-04T07:42:50.993933Z",
     "start_time": "2018-11-04T07:42:50.954269Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-04T07:35:21.585455Z",
     "start_time": "2018-11-04T07:35:06.931128Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                  | 0/2402 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Encoding dataset...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'n_batch_train': 2,\n",
       " 'n_train': 2402,\n",
       " 'n_updates_total': 3603,\n",
       " 'n_valid': 374,\n",
       " 'n_vocab': 40478}"
      ]
     },
     "execution_count": 211,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Encoding dataset...\")\n",
    "((trX1, trX2, trX3, trY), (vaX1, vaX2, vaX3, vaY),\n",
    " (teX1, teX2, teX3)) = encode_dataset(\n",
    "     *rocstories(data_dir, n_valid=args.n_valid), encoder=text_encoder)\n",
    "\n",
    "encoder['_start_'] = len(encoder)\n",
    "encoder['_delimiter_'] = len(encoder)\n",
    "encoder['_classify_'] = len(encoder)\n",
    "clf_token = encoder['_classify_']\n",
    "n_special = 3\n",
    "max_len = n_ctx // 2 - 2\n",
    "\n",
    "n_ctx = min(\n",
    "    max([\n",
    "        len(x1[:max_len]) + max(len(x2[:max_len]), len(x3[:max_len]))\n",
    "        for x1, x2, x3 in zip(trX1, trX2, trX3)\n",
    "    ] + [\n",
    "        len(x1[:max_len]) + max(len(x2[:max_len]), len(x3[:max_len]))\n",
    "        for x1, x2, x3 in zip(vaX1, vaX2, vaX3)\n",
    "    ] + [\n",
    "        len(x1[:max_len]) + max(len(x2[:max_len]), len(x3[:max_len]))\n",
    "        for x1, x2, x3 in zip(teX1, teX2, teX3)\n",
    "    ]) + 3, n_ctx)\n",
    "vocab = n_vocab + n_special + n_ctx\n",
    "\n",
    "trX, trM = transform_roc(trX1, trX2, trX3)\n",
    "vaX, vaM = transform_roc(vaX1, vaX2, vaX3)\n",
    "\n",
    "if submit:\n",
    "    teX, teM = transform_roc(teX1, teX2, teX3)\n",
    "\n",
    "n_train = len(trY)\n",
    "n_valid = len(vaY)\n",
    "n_batch_train = args.n_batch * max(n_gpu, 1)\n",
    "n_updates_total = (n_train // n_batch_train) * args.n_iter\n",
    "dict(n_train=n_train, n_valid=n_valid, n_vocab=n_vocab, n_batch_train=n_batch_train, n_updates_total=n_updates_total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-04T07:35:21.630262Z",
     "start_time": "2018-11-04T07:35:21.588736Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2402, 2, 349, 2)"
      ]
     },
     "execution_count": 212,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trX.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model, loss, opt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-04T05:19:52.414808Z",
     "start_time": "2018-11-04T05:19:43.717017Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/wassname/.pyenv/versions/3.5.3/envs/jupyter3/lib/python3.5/site-packages/torch/nn/functional.py:52: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.\n",
      "  warnings.warn(warning.format(ret))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading weights...\n"
     ]
    }
   ],
   "source": [
    "# model\n",
    "dh_model = DoubleHeadModel(args, clf_token, 'multiple_choice', vocab, n_ctx)\n",
    "\n",
    "# loss, optimizer\n",
    "criterion = nn.CrossEntropyLoss(reduce=False)\n",
    "model_opt = OpenAIAdam(\n",
    "    dh_model.parameters(),\n",
    "    lr=args.lr,\n",
    "    schedule=args.lr_schedule,\n",
    "    warmup=args.lr_warmup,\n",
    "    t_total=n_updates_total,\n",
    "    b1=args.b1,\n",
    "    b2=args.b2,\n",
    "    e=args.e,\n",
    "    l2=args.l2,\n",
    "    vector_l2=args.vector_l2,\n",
    "    max_grad_norm=args.max_grad_norm)\n",
    "compute_loss_fct = LMLossCompute(criterion, model_opt)\n",
    "## move up?\n",
    "# load pretrained model\n",
    "load_openai_pretrained_model(\n",
    "    dh_model.transformer, n_ctx=n_ctx, n_special=n_special)\n",
    "\n",
    "dh_model.to(device)\n",
    "dh_model = nn.DataParallel(dh_model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-04T05:19:52.473049Z",
     "start_time": "2018-11-04T05:19:52.419773Z"
    }
   },
   "outputs": [],
   "source": [
    "n_updates = 0\n",
    "n_epochs = 0\n",
    "if dataset != 'stsb':\n",
    "    trYt = trY\n",
    "\n",
    "# save params\n",
    "if submit:\n",
    "    path = os.path.join(save_dir, desc, 'best_params')\n",
    "    torch.save(dh_model.state_dict(), make_path(path))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-04T05:50:29.996293Z",
     "start_time": "2018-11-04T05:19:52.476167Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|                                                  | 0/1201 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "running epoch 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 83%|█████████████████████████████████▎      | 999/1201 [07:47<01:35,  2.12it/s]\n",
      "  0%|                                                   | 0/187 [00:00<?, ?it/s]\u001b[A\n",
      "  1%|▏                                          | 1/187 [00:00<00:21,  8.55it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logging\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  1%|▍                                          | 2/187 [00:00<00:22,  8.33it/s]\u001b[A\n",
      "  2%|▋                                          | 3/187 [00:00<00:22,  8.25it/s]\u001b[A\n",
      "  2%|▉                                          | 4/187 [00:00<00:22,  8.12it/s]\u001b[A\n",
      "  3%|█▏                                         | 5/187 [00:00<00:22,  8.11it/s]\u001b[A\n",
      "  3%|█▍                                         | 6/187 [00:00<00:22,  8.04it/s]\u001b[A\n",
      "  4%|█▌                                         | 7/187 [00:00<00:22,  8.01it/s]\u001b[A\n",
      "  4%|█▊                                         | 8/187 [00:00<00:22,  8.05it/s]\u001b[A\n",
      "  5%|██                                         | 9/187 [00:01<00:21,  8.15it/s]\u001b[A\n",
      "  5%|██▏                                       | 10/187 [00:01<00:21,  8.22it/s]\u001b[A\n",
      "  6%|██▍                                       | 11/187 [00:01<00:21,  8.26it/s]\u001b[A\n",
      "  6%|██▋                                       | 12/187 [00:01<00:21,  8.30it/s]\u001b[A\n",
      "  7%|██▉                                       | 13/187 [00:01<00:20,  8.38it/s]\u001b[A\n",
      "  7%|███▏                                      | 14/187 [00:01<00:20,  8.39it/s]\u001b[A\n",
      "  8%|███▎                                      | 15/187 [00:01<00:20,  8.27it/s]\u001b[A\n",
      "  9%|███▌                                      | 16/187 [00:01<00:20,  8.31it/s]\u001b[A\n",
      "  9%|███▊                                      | 17/187 [00:02<00:20,  8.24it/s]\u001b[A\n",
      " 10%|████                                      | 18/187 [00:02<00:20,  8.21it/s]\u001b[A\n",
      " 10%|████▎                                     | 19/187 [00:02<00:20,  8.22it/s]\u001b[A\n",
      " 11%|████▍                                     | 20/187 [00:02<00:20,  8.10it/s]\u001b[A\n",
      " 11%|████▋                                     | 21/187 [00:02<00:20,  8.05it/s]\u001b[A\n",
      " 12%|████▉                                     | 22/187 [00:02<00:20,  8.03it/s]\u001b[A\n",
      " 12%|█████▏                                    | 23/187 [00:02<00:20,  8.06it/s]\u001b[A\n",
      " 13%|█████▍                                    | 24/187 [00:02<00:20,  8.09it/s]\u001b[A\n",
      " 13%|█████▌                                    | 25/187 [00:03<00:20,  8.02it/s]\u001b[A\n",
      " 14%|█████▊                                    | 26/187 [00:03<00:19,  8.10it/s]\u001b[A\n",
      " 14%|██████                                    | 27/187 [00:03<00:19,  8.22it/s]\u001b[A\n",
      " 15%|██████▎                                   | 28/187 [00:03<00:19,  8.31it/s]\u001b[A\n",
      " 16%|██████▌                                   | 29/187 [00:03<00:18,  8.35it/s]\u001b[A\n",
      " 16%|██████▋                                   | 30/187 [00:03<00:18,  8.30it/s]\u001b[A\n",
      " 17%|██████▉                                   | 31/187 [00:03<00:19,  8.12it/s]\u001b[A\n",
      " 17%|███████▏                                  | 32/187 [00:03<00:18,  8.22it/s]\u001b[A\n",
      " 18%|███████▍                                  | 33/187 [00:04<00:18,  8.24it/s]\u001b[A\n",
      " 18%|███████▋                                  | 34/187 [00:04<00:18,  8.30it/s]\u001b[A\n",
      " 19%|███████▊                                  | 35/187 [00:04<00:18,  8.30it/s]\u001b[A\n",
      " 19%|████████                                  | 36/187 [00:04<00:18,  8.21it/s]\u001b[A\n",
      " 20%|████████▎                                 | 37/187 [00:04<00:18,  8.21it/s]\u001b[A\n",
      " 20%|████████▌                                 | 38/187 [00:04<00:18,  8.25it/s]\u001b[A\n",
      " 21%|████████▊                                 | 39/187 [00:04<00:17,  8.28it/s]\u001b[A\n",
      " 21%|████████▉                                 | 40/187 [00:04<00:17,  8.18it/s]\u001b[A\n",
      " 22%|█████████▏                                | 41/187 [00:05<00:17,  8.11it/s]\u001b[A\n",
      " 22%|█████████▍                                | 42/187 [00:05<00:18,  8.05it/s]\u001b[A\n",
      " 23%|█████████▋                                | 43/187 [00:05<00:17,  8.02it/s]\u001b[A\n",
      " 24%|█████████▉                                | 44/187 [00:05<00:17,  8.08it/s]\u001b[A\n",
      " 24%|██████████                                | 45/187 [00:05<00:17,  8.10it/s]\u001b[A\n",
      " 25%|██████████▎                               | 46/187 [00:05<00:17,  8.21it/s]\u001b[A\n",
      " 25%|██████████▌                               | 47/187 [00:05<00:17,  8.20it/s]\u001b[A\n",
      " 26%|██████████▊                               | 48/187 [00:05<00:17,  8.09it/s]\u001b[A\n",
      " 26%|███████████                               | 49/187 [00:06<00:17,  8.02it/s]\u001b[A\n",
      " 27%|███████████▏                              | 50/187 [00:06<00:17,  8.00it/s]\u001b[A\n",
      " 27%|███████████▍                              | 51/187 [00:06<00:17,  7.82it/s]\u001b[A\n",
      " 28%|███████████▋                              | 52/187 [00:06<00:17,  7.89it/s]\u001b[A\n",
      " 28%|███████████▉                              | 53/187 [00:06<00:16,  7.92it/s]\u001b[A\n",
      " 29%|████████████▏                             | 54/187 [00:06<00:16,  7.97it/s]\u001b[A\n",
      " 29%|████████████▎                             | 55/187 [00:06<00:16,  8.00it/s]\u001b[A\n",
      " 30%|████████████▌                             | 56/187 [00:06<00:16,  8.10it/s]\u001b[A\n",
      " 30%|████████████▊                             | 57/187 [00:07<00:15,  8.17it/s]\u001b[A\n",
      " 31%|█████████████                             | 58/187 [00:07<00:15,  8.17it/s]\u001b[A\n",
      " 32%|█████████████▎                            | 59/187 [00:07<00:15,  8.09it/s]\u001b[A\n",
      " 32%|█████████████▍                            | 60/187 [00:07<00:15,  8.05it/s]\u001b[A\n",
      " 33%|█████████████▋                            | 61/187 [00:07<00:15,  8.01it/s]\u001b[A\n",
      " 33%|█████████████▉                            | 62/187 [00:07<00:15,  7.93it/s]\u001b[A\n",
      " 34%|██████████████▏                           | 63/187 [00:07<00:15,  7.88it/s]\u001b[A\n",
      " 34%|██████████████▎                           | 64/187 [00:07<00:15,  7.87it/s]\u001b[A\n",
      " 35%|██████████████▌                           | 65/187 [00:08<00:15,  7.99it/s]\u001b[A\n",
      " 35%|██████████████▊                           | 66/187 [00:08<00:14,  8.14it/s]\u001b[A\n",
      " 36%|███████████████                           | 67/187 [00:08<00:14,  8.19it/s]\u001b[A\n",
      " 36%|███████████████▎                          | 68/187 [00:08<00:14,  8.28it/s]\u001b[A\n",
      " 37%|███████████████▍                          | 69/187 [00:08<00:14,  8.29it/s]\u001b[A\n",
      " 37%|███████████████▋                          | 70/187 [00:08<00:14,  8.30it/s]\u001b[A\n",
      " 38%|███████████████▉                          | 71/187 [00:08<00:13,  8.32it/s]\u001b[A\n",
      " 39%|████████████████▏                         | 72/187 [00:08<00:13,  8.35it/s]\u001b[A\n",
      " 39%|████████████████▍                         | 73/187 [00:08<00:13,  8.26it/s]\u001b[A\n",
      " 40%|████████████████▌                         | 74/187 [00:09<00:13,  8.25it/s]\u001b[A\n",
      " 40%|████████████████▊                         | 75/187 [00:09<00:13,  8.31it/s]\u001b[A\n",
      " 41%|█████████████████                         | 76/187 [00:09<00:13,  8.27it/s]\u001b[A\n",
      " 41%|█████████████████▎                        | 77/187 [00:09<00:13,  8.20it/s]\u001b[A\n",
      " 42%|█████████████████▌                        | 78/187 [00:09<00:13,  8.11it/s]\u001b[A\n",
      " 42%|█████████████████▋                        | 79/187 [00:09<00:13,  7.99it/s]\u001b[A\n",
      " 43%|█████████████████▉                        | 80/187 [00:09<00:13,  7.68it/s]\u001b[A\n",
      " 43%|██████████████████▏                       | 81/187 [00:09<00:13,  7.82it/s]\u001b[A\n",
      " 44%|██████████████████▍                       | 82/187 [00:10<00:13,  8.01it/s]\u001b[A\n",
      " 44%|██████████████████▋                       | 83/187 [00:10<00:12,  8.05it/s]\u001b[A\n",
      " 45%|██████████████████▊                       | 84/187 [00:10<00:12,  8.14it/s]\u001b[A\n",
      " 45%|███████████████████                       | 85/187 [00:10<00:12,  7.98it/s]\u001b[A\n",
      " 46%|███████████████████▎                      | 86/187 [00:10<00:12,  7.96it/s]\u001b[A\n",
      " 47%|███████████████████▌                      | 87/187 [00:10<00:12,  8.03it/s]\u001b[A\n",
      " 47%|███████████████████▊                      | 88/187 [00:10<00:12,  8.11it/s]\u001b[A\n",
      " 48%|███████████████████▉                      | 89/187 [00:10<00:12,  8.14it/s]\u001b[A\n",
      " 48%|████████████████████▏                     | 90/187 [00:11<00:12,  8.06it/s]\u001b[A\n",
      " 49%|████████████████████▍                     | 91/187 [00:11<00:11,  8.02it/s]\u001b[A\n",
      " 49%|████████████████████▋                     | 92/187 [00:11<00:11,  8.03it/s]\u001b[A\n",
      " 50%|████████████████████▉                     | 93/187 [00:11<00:11,  8.01it/s]\u001b[A\n",
      " 50%|█████████████████████                     | 94/187 [00:11<00:11,  7.97it/s]\u001b[A\n",
      " 51%|█████████████████████▎                    | 95/187 [00:11<00:11,  8.04it/s]\u001b[A\n",
      " 51%|█████████████████████▌                    | 96/187 [00:11<00:11,  8.00it/s]\u001b[A\n",
      " 52%|█████████████████████▊                    | 97/187 [00:11<00:11,  8.10it/s]\u001b[A\n",
      " 52%|██████████████████████                    | 98/187 [00:12<00:10,  8.12it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 53%|██████████████████████▏                   | 99/187 [00:12<00:10,  8.22it/s]\u001b[A\n",
      " 53%|█████████████████████▉                   | 100/187 [00:12<00:10,  8.29it/s]\u001b[A\n",
      " 54%|██████████████████████▏                  | 101/187 [00:12<00:10,  8.27it/s]\u001b[A\n",
      " 55%|██████████████████████▎                  | 102/187 [00:12<00:10,  8.36it/s]\u001b[A\n",
      " 55%|██████████████████████▌                  | 103/187 [00:12<00:10,  8.32it/s]\u001b[A\n",
      " 56%|██████████████████████▊                  | 104/187 [00:12<00:09,  8.30it/s]\u001b[A\n",
      " 56%|███████████████████████                  | 105/187 [00:12<00:09,  8.29it/s]\u001b[A\n",
      " 57%|███████████████████████▏                 | 106/187 [00:13<00:09,  8.34it/s]\u001b[A\n",
      " 57%|███████████████████████▍                 | 107/187 [00:13<00:09,  8.10it/s]\u001b[A\n",
      " 58%|███████████████████████▋                 | 108/187 [00:13<00:09,  8.12it/s]\u001b[A\n",
      " 58%|███████████████████████▉                 | 109/187 [00:13<00:09,  8.14it/s]\u001b[A\n",
      " 59%|████████████████████████                 | 110/187 [00:13<00:09,  8.26it/s]\u001b[A\n",
      " 59%|████████████████████████▎                | 111/187 [00:13<00:09,  8.19it/s]\u001b[A\n",
      " 60%|████████████████████████▌                | 112/187 [00:13<00:09,  8.09it/s]\u001b[A\n",
      " 60%|████████████████████████▊                | 113/187 [00:13<00:09,  8.04it/s]\u001b[A\n",
      " 61%|████████████████████████▉                | 114/187 [00:14<00:09,  8.03it/s]\u001b[A\n",
      " 61%|█████████████████████████▏               | 115/187 [00:14<00:08,  8.05it/s]\u001b[A\n",
      " 62%|█████████████████████████▍               | 116/187 [00:14<00:08,  8.18it/s]\u001b[A\n",
      " 63%|█████████████████████████▋               | 117/187 [00:14<00:08,  8.25it/s]\u001b[A\n",
      " 63%|█████████████████████████▊               | 118/187 [00:14<00:08,  8.31it/s]\u001b[A\n",
      " 64%|██████████████████████████               | 119/187 [00:14<00:08,  8.20it/s]\u001b[A\n",
      " 64%|██████████████████████████▎              | 120/187 [00:14<00:08,  8.10it/s]\u001b[A\n",
      " 65%|██████████████████████████▌              | 121/187 [00:14<00:08,  8.01it/s]\u001b[A\n",
      " 65%|██████████████████████████▋              | 122/187 [00:15<00:08,  8.00it/s]\u001b[A\n",
      " 66%|██████████████████████████▉              | 123/187 [00:15<00:08,  7.92it/s]\u001b[A\n",
      " 66%|███████████████████████████▏             | 124/187 [00:15<00:07,  7.88it/s]\u001b[A\n",
      " 67%|███████████████████████████▍             | 125/187 [00:15<00:07,  7.94it/s]\u001b[A\n",
      " 67%|███████████████████████████▋             | 126/187 [00:15<00:07,  8.13it/s]\u001b[A\n",
      " 68%|███████████████████████████▊             | 127/187 [00:15<00:07,  8.25it/s]\u001b[A\n",
      " 68%|████████████████████████████             | 128/187 [00:15<00:07,  8.22it/s]\u001b[A\n",
      " 69%|████████████████████████████▎            | 129/187 [00:15<00:07,  8.11it/s]\u001b[A\n",
      " 70%|████████████████████████████▌            | 130/187 [00:16<00:07,  8.00it/s]\u001b[A\n",
      " 70%|████████████████████████████▋            | 131/187 [00:16<00:06,  8.03it/s]\u001b[A\n",
      " 71%|████████████████████████████▉            | 132/187 [00:16<00:06,  8.12it/s]\u001b[A\n",
      " 71%|█████████████████████████████▏           | 133/187 [00:16<00:06,  8.18it/s]\u001b[A\n",
      " 72%|█████████████████████████████▍           | 134/187 [00:16<00:06,  8.09it/s]\u001b[A\n",
      " 72%|█████████████████████████████▌           | 135/187 [00:16<00:06,  8.16it/s]\u001b[A\n",
      " 73%|█████████████████████████████▊           | 136/187 [00:16<00:06,  7.94it/s]\u001b[A\n",
      " 73%|██████████████████████████████           | 137/187 [00:16<00:06,  7.91it/s]\u001b[A\n",
      " 74%|██████████████████████████████▎          | 138/187 [00:17<00:06,  7.93it/s]\u001b[A\n",
      " 74%|██████████████████████████████▍          | 139/187 [00:17<00:06,  7.95it/s]\u001b[A\n",
      " 75%|██████████████████████████████▋          | 140/187 [00:17<00:05,  8.01it/s]\u001b[A\n",
      " 75%|██████████████████████████████▉          | 141/187 [00:17<00:05,  8.08it/s]\u001b[A\n",
      " 76%|███████████████████████████████▏         | 142/187 [00:17<00:05,  8.21it/s]\u001b[A\n",
      " 76%|███████████████████████████████▎         | 143/187 [00:17<00:05,  8.04it/s]\u001b[A\n",
      " 77%|███████████████████████████████▌         | 144/187 [00:17<00:05,  8.03it/s]\u001b[A\n",
      " 78%|███████████████████████████████▊         | 145/187 [00:17<00:05,  7.99it/s]\u001b[A\n",
      " 78%|████████████████████████████████         | 146/187 [00:17<00:05,  8.04it/s]\u001b[A\n",
      " 79%|████████████████████████████████▏        | 147/187 [00:18<00:04,  8.12it/s]\u001b[A\n",
      " 79%|████████████████████████████████▍        | 148/187 [00:18<00:04,  8.21it/s]\u001b[A\n",
      " 80%|████████████████████████████████▋        | 149/187 [00:18<00:04,  8.24it/s]\u001b[A\n",
      " 80%|████████████████████████████████▉        | 150/187 [00:18<00:04,  8.30it/s]\u001b[A\n",
      " 81%|█████████████████████████████████        | 151/187 [00:18<00:04,  8.30it/s]\u001b[A\n",
      " 81%|█████████████████████████████████▎       | 152/187 [00:18<00:04,  8.23it/s]\u001b[A\n",
      " 82%|█████████████████████████████████▌       | 153/187 [00:18<00:04,  8.20it/s]\u001b[A\n",
      " 82%|█████████████████████████████████▊       | 154/187 [00:18<00:03,  8.27it/s]\u001b[A\n",
      " 83%|█████████████████████████████████▉       | 155/187 [00:19<00:03,  8.18it/s]\u001b[A\n",
      " 83%|██████████████████████████████████▏      | 156/187 [00:19<00:03,  8.10it/s]\u001b[A\n",
      " 84%|██████████████████████████████████▍      | 157/187 [00:19<00:03,  8.14it/s]\u001b[A\n",
      " 84%|██████████████████████████████████▋      | 158/187 [00:19<00:03,  8.21it/s]\u001b[A\n",
      " 85%|██████████████████████████████████▊      | 159/187 [00:19<00:03,  8.33it/s]\u001b[A\n",
      " 86%|███████████████████████████████████      | 160/187 [00:19<00:03,  8.28it/s]\u001b[A\n",
      " 86%|███████████████████████████████████▎     | 161/187 [00:19<00:03,  8.13it/s]\u001b[A\n",
      " 87%|███████████████████████████████████▌     | 162/187 [00:19<00:03,  8.04it/s]\u001b[A\n",
      " 87%|███████████████████████████████████▋     | 163/187 [00:20<00:03,  7.90it/s]\u001b[A\n",
      " 88%|███████████████████████████████████▉     | 164/187 [00:20<00:02,  7.96it/s]\u001b[A\n",
      " 88%|████████████████████████████████████▏    | 165/187 [00:20<00:02,  8.03it/s]\u001b[A\n",
      " 89%|████████████████████████████████████▍    | 166/187 [00:20<00:02,  8.20it/s]\u001b[A\n",
      " 89%|████████████████████████████████████▌    | 167/187 [00:20<00:02,  8.25it/s]\u001b[A\n",
      " 90%|████████████████████████████████████▊    | 168/187 [00:20<00:02,  8.31it/s]\u001b[A\n",
      " 90%|█████████████████████████████████████    | 169/187 [00:20<00:02,  8.26it/s]\u001b[A\n",
      " 91%|█████████████████████████████████████▎   | 170/187 [00:20<00:02,  8.22it/s]\u001b[A\n",
      " 91%|█████████████████████████████████████▍   | 171/187 [00:21<00:01,  8.33it/s]\u001b[A\n",
      " 92%|█████████████████████████████████████▋   | 172/187 [00:21<00:01,  8.38it/s]\u001b[A\n",
      " 93%|█████████████████████████████████████▉   | 173/187 [00:21<00:01,  8.42it/s]\u001b[A\n",
      " 93%|██████████████████████████████████████▏  | 174/187 [00:21<00:01,  8.42it/s]\u001b[A\n",
      " 94%|██████████████████████████████████████▎  | 175/187 [00:21<00:01,  8.29it/s]\u001b[A\n",
      " 94%|██████████████████████████████████████▌  | 176/187 [00:21<00:01,  8.22it/s]\u001b[A\n",
      " 95%|██████████████████████████████████████▊  | 177/187 [00:21<00:01,  8.11it/s]\u001b[A\n",
      " 95%|███████████████████████████████████████  | 178/187 [00:21<00:01,  8.07it/s]\u001b[A\n",
      " 96%|███████████████████████████████████████▏ | 179/187 [00:22<00:00,  8.18it/s]\u001b[A\n",
      " 96%|███████████████████████████████████████▍ | 180/187 [00:22<00:00,  8.17it/s]\u001b[A\n",
      " 97%|███████████████████████████████████████▋ | 181/187 [00:22<00:00,  8.15it/s]\u001b[A\n",
      " 97%|███████████████████████████████████████▉ | 182/187 [00:22<00:00,  8.19it/s]\u001b[A\n",
      " 98%|████████████████████████████████████████ | 183/187 [00:22<00:00,  8.25it/s]\u001b[A\n",
      " 98%|████████████████████████████████████████▎| 184/187 [00:22<00:00,  8.36it/s]\u001b[A\n",
      " 99%|████████████████████████████████████████▌| 185/187 [00:22<00:00,  8.38it/s]\u001b[A\n",
      " 99%|████████████████████████████████████████▊| 186/187 [00:22<00:00,  8.25it/s]\u001b[A\n",
      "100%|█████████████████████████████████████████| 187/187 [00:22<00:00,  8.13it/s]\u001b[A\n",
      "                                                                                \u001b[A\n",
      "  0%|                                                   | 0/187 [00:00<?, ?it/s]\u001b[A\n",
      "  1%|▏                                          | 1/187 [00:00<00:22,  8.20it/s]\u001b[A\n",
      "  1%|▍                                          | 2/187 [00:00<00:22,  8.22it/s]\u001b[A\n",
      "  2%|▋                                          | 3/187 [00:00<00:22,  8.28it/s]\u001b[A\n",
      "  2%|▉                                          | 4/187 [00:00<00:22,  8.25it/s]\u001b[A\n",
      "  3%|█▏                                         | 5/187 [00:00<00:22,  8.17it/s]\u001b[A\n",
      "  3%|█▍                                         | 6/187 [00:00<00:22,  8.09it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|█▌                                         | 7/187 [00:00<00:22,  8.17it/s]\u001b[A\n",
      "  4%|█▊                                         | 8/187 [00:00<00:21,  8.15it/s]\u001b[A\n",
      "  5%|██                                         | 9/187 [00:01<00:21,  8.28it/s]\u001b[A\n",
      "  5%|██▏                                       | 10/187 [00:01<00:21,  8.37it/s]\u001b[A\n",
      "  6%|██▍                                       | 11/187 [00:01<00:21,  8.25it/s]\u001b[A\n",
      "  6%|██▋                                       | 12/187 [00:01<00:21,  7.96it/s]\u001b[A\n",
      "  7%|██▉                                       | 13/187 [00:01<00:21,  8.00it/s]\u001b[A\n",
      "  7%|███▏                                      | 14/187 [00:01<00:21,  8.16it/s]\u001b[A\n",
      "  8%|███▎                                      | 15/187 [00:01<00:20,  8.25it/s]\u001b[A\n",
      "  9%|███▌                                      | 16/187 [00:01<00:20,  8.15it/s]\u001b[A\n",
      "  9%|███▊                                      | 17/187 [00:02<00:20,  8.12it/s]\u001b[A\n",
      " 10%|████                                      | 18/187 [00:02<00:20,  8.05it/s]\u001b[A\n",
      " 10%|████▎                                     | 19/187 [00:02<00:21,  7.99it/s]\u001b[A\n",
      " 11%|████▍                                     | 20/187 [00:02<00:21,  7.77it/s]\u001b[A\n",
      " 11%|████▋                                     | 21/187 [00:02<00:21,  7.83it/s]\u001b[A\n",
      " 12%|████▉                                     | 22/187 [00:02<00:20,  7.87it/s]\u001b[A\n",
      " 12%|█████▏                                    | 23/187 [00:02<00:20,  7.88it/s]\u001b[A\n",
      " 13%|█████▍                                    | 24/187 [00:02<00:20,  7.92it/s]\u001b[A\n",
      " 13%|█████▌                                    | 25/187 [00:03<00:20,  7.95it/s]\u001b[A\n",
      " 14%|█████▊                                    | 26/187 [00:03<00:20,  7.99it/s]\u001b[A\n",
      " 14%|██████                                    | 27/187 [00:03<00:20,  7.99it/s]\u001b[A\n",
      " 15%|██████▎                                   | 28/187 [00:03<00:19,  8.05it/s]\u001b[A\n",
      " 16%|██████▌                                   | 29/187 [00:03<00:19,  8.19it/s]\u001b[A\n",
      " 16%|██████▋                                   | 30/187 [00:03<00:18,  8.30it/s]\u001b[A\n",
      " 17%|██████▉                                   | 31/187 [00:03<00:18,  8.29it/s]\u001b[A\n",
      " 17%|███████▏                                  | 32/187 [00:03<00:18,  8.33it/s]\u001b[A\n",
      " 18%|███████▍                                  | 33/187 [00:04<00:18,  8.43it/s]\u001b[A\n",
      " 18%|███████▋                                  | 34/187 [00:04<00:18,  8.43it/s]\u001b[A\n",
      " 19%|███████▊                                  | 35/187 [00:04<00:17,  8.45it/s]\u001b[A\n",
      " 19%|████████                                  | 36/187 [00:04<00:17,  8.41it/s]\u001b[A\n",
      " 20%|████████▎                                 | 37/187 [00:04<00:17,  8.42it/s]\u001b[A\n",
      " 20%|████████▌                                 | 38/187 [00:04<00:17,  8.49it/s]\u001b[A\n",
      " 21%|████████▊                                 | 39/187 [00:04<00:17,  8.53it/s]\u001b[A\n",
      " 21%|████████▉                                 | 40/187 [00:04<00:17,  8.52it/s]\u001b[A\n",
      " 22%|█████████▏                                | 41/187 [00:05<00:17,  8.50it/s]\u001b[A\n",
      " 22%|█████████▍                                | 42/187 [00:05<00:17,  8.53it/s]\u001b[A\n",
      " 23%|█████████▋                                | 43/187 [00:05<00:16,  8.56it/s]\u001b[A\n",
      " 24%|█████████▉                                | 44/187 [00:05<00:16,  8.53it/s]\u001b[A\n",
      " 24%|██████████                                | 45/187 [00:05<00:16,  8.43it/s]\u001b[A\n",
      " 25%|██████████▎                               | 46/187 [00:05<00:16,  8.47it/s]\u001b[A\n",
      " 25%|██████████▌                               | 47/187 [00:05<00:16,  8.51it/s]\u001b[A\n",
      " 26%|██████████▊                               | 48/187 [00:05<00:16,  8.37it/s]\u001b[A\n",
      " 26%|███████████                               | 49/187 [00:05<00:16,  8.27it/s]\u001b[A\n",
      " 27%|███████████▏                              | 50/187 [00:06<00:16,  8.36it/s]\u001b[A\n",
      " 27%|███████████▍                              | 51/187 [00:06<00:16,  8.23it/s]\u001b[A\n",
      " 28%|███████████▋                              | 52/187 [00:06<00:16,  8.10it/s]\u001b[A\n",
      " 28%|███████████▉                              | 53/187 [00:06<00:16,  8.11it/s]\u001b[A\n",
      " 29%|████████████▏                             | 54/187 [00:06<00:16,  8.20it/s]\u001b[A\n",
      " 29%|████████████▎                             | 55/187 [00:06<00:15,  8.26it/s]\u001b[A\n",
      " 30%|████████████▌                             | 56/187 [00:06<00:15,  8.20it/s]\u001b[A\n",
      " 30%|████████████▊                             | 57/187 [00:06<00:15,  8.28it/s]\u001b[A\n",
      " 31%|█████████████                             | 58/187 [00:07<00:15,  8.33it/s]\u001b[A\n",
      " 32%|█████████████▎                            | 59/187 [00:07<00:15,  8.36it/s]\u001b[A\n",
      " 32%|█████████████▍                            | 60/187 [00:07<00:15,  8.18it/s]\u001b[A\n",
      " 33%|█████████████▋                            | 61/187 [00:07<00:15,  8.05it/s]\u001b[A\n",
      " 33%|█████████████▉                            | 62/187 [00:07<00:15,  7.93it/s]\u001b[A\n",
      " 34%|██████████████▏                           | 63/187 [00:07<00:15,  7.94it/s]\u001b[A\n",
      " 34%|██████████████▎                           | 64/187 [00:07<00:15,  8.05it/s]\u001b[A\n",
      " 35%|██████████████▌                           | 65/187 [00:07<00:14,  8.18it/s]\u001b[A\n",
      " 35%|██████████████▊                           | 66/187 [00:08<00:14,  8.29it/s]\u001b[A\n",
      " 36%|███████████████                           | 67/187 [00:08<00:14,  8.39it/s]\u001b[A\n",
      " 36%|███████████████▎                          | 68/187 [00:08<00:14,  8.31it/s]\u001b[A\n",
      " 37%|███████████████▍                          | 69/187 [00:08<00:14,  8.31it/s]\u001b[A\n",
      " 37%|███████████████▋                          | 70/187 [00:08<00:13,  8.41it/s]\u001b[A\n",
      " 38%|███████████████▉                          | 71/187 [00:08<00:13,  8.47it/s]\u001b[A\n",
      " 39%|████████████████▏                         | 72/187 [00:08<00:13,  8.50it/s]\u001b[A\n",
      " 39%|████████████████▍                         | 73/187 [00:08<00:13,  8.38it/s]\u001b[A\n",
      " 40%|████████████████▌                         | 74/187 [00:08<00:13,  8.23it/s]\u001b[A\n",
      " 40%|████████████████▊                         | 75/187 [00:09<00:13,  8.33it/s]\u001b[A\n",
      " 41%|█████████████████                         | 76/187 [00:09<00:13,  8.43it/s]\u001b[A\n",
      " 41%|█████████████████▎                        | 77/187 [00:09<00:13,  8.30it/s]\u001b[A\n",
      " 42%|█████████████████▌                        | 78/187 [00:09<00:13,  8.20it/s]\u001b[A\n",
      " 42%|█████████████████▋                        | 79/187 [00:09<00:12,  8.32it/s]\u001b[A\n",
      " 43%|█████████████████▉                        | 80/187 [00:09<00:12,  8.41it/s]\u001b[A\n",
      " 43%|██████████████████▏                       | 81/187 [00:09<00:12,  8.36it/s]\u001b[A\n",
      " 44%|██████████████████▍                       | 82/187 [00:09<00:12,  8.38it/s]\u001b[A\n",
      " 44%|██████████████████▋                       | 83/187 [00:10<00:12,  8.38it/s]\u001b[A\n",
      " 45%|██████████████████▊                       | 84/187 [00:10<00:12,  8.46it/s]\u001b[A\n",
      " 45%|███████████████████                       | 85/187 [00:10<00:12,  8.31it/s]\u001b[A\n",
      " 46%|███████████████████▎                      | 86/187 [00:10<00:12,  8.37it/s]\u001b[A\n",
      " 47%|███████████████████▌                      | 87/187 [00:10<00:11,  8.39it/s]\u001b[A\n",
      " 47%|███████████████████▊                      | 88/187 [00:10<00:11,  8.41it/s]\u001b[A\n",
      " 48%|███████████████████▉                      | 89/187 [00:10<00:11,  8.38it/s]\u001b[A\n",
      " 48%|████████████████████▏                     | 90/187 [00:10<00:11,  8.27it/s]\u001b[A\n",
      " 49%|████████████████████▍                     | 91/187 [00:11<00:11,  8.18it/s]\u001b[A\n",
      " 49%|████████████████████▋                     | 92/187 [00:11<00:11,  8.30it/s]\u001b[A\n",
      " 50%|████████████████████▉                     | 93/187 [00:11<00:11,  8.38it/s]\u001b[A\n",
      " 50%|█████████████████████                     | 94/187 [00:11<00:11,  8.45it/s]\u001b[A\n",
      " 51%|█████████████████████▎                    | 95/187 [00:11<00:10,  8.46it/s]\u001b[A\n",
      " 51%|█████████████████████▌                    | 96/187 [00:11<00:11,  8.12it/s]\u001b[A\n",
      " 52%|█████████████████████▊                    | 97/187 [00:11<00:11,  8.09it/s]\u001b[A\n",
      " 52%|██████████████████████                    | 98/187 [00:11<00:11,  8.06it/s]\u001b[A\n",
      " 53%|██████████████████████▏                   | 99/187 [00:12<00:10,  8.05it/s]\u001b[A\n",
      " 53%|█████████████████████▉                   | 100/187 [00:12<00:10,  8.18it/s]\u001b[A\n",
      " 54%|██████████████████████▏                  | 101/187 [00:12<00:10,  8.28it/s]\u001b[A\n",
      " 55%|██████████████████████▎                  | 102/187 [00:12<00:10,  8.38it/s]\u001b[A\n",
      " 55%|██████████████████████▌                  | 103/187 [00:12<00:09,  8.42it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 56%|██████████████████████▊                  | 104/187 [00:12<00:09,  8.44it/s]\u001b[A\n",
      " 56%|███████████████████████                  | 105/187 [00:12<00:09,  8.48it/s]\u001b[A\n",
      " 57%|███████████████████████▏                 | 106/187 [00:12<00:09,  8.41it/s]\u001b[A\n",
      " 57%|███████████████████████▍                 | 107/187 [00:12<00:09,  8.42it/s]\u001b[A\n",
      " 58%|███████████████████████▋                 | 108/187 [00:13<00:09,  8.43it/s]\u001b[A\n",
      " 58%|███████████████████████▉                 | 109/187 [00:13<00:09,  8.44it/s]\u001b[A\n",
      " 59%|████████████████████████                 | 110/187 [00:13<00:09,  8.28it/s]\u001b[A\n",
      " 59%|████████████████████████▎                | 111/187 [00:13<00:09,  7.99it/s]\u001b[A\n",
      " 60%|████████████████████████▌                | 112/187 [00:13<00:09,  7.82it/s]\u001b[A\n",
      " 60%|████████████████████████▊                | 113/187 [00:13<00:09,  7.79it/s]\u001b[A\n",
      " 61%|████████████████████████▉                | 114/187 [00:13<00:09,  7.99it/s]\u001b[A\n",
      " 61%|█████████████████████████▏               | 115/187 [00:13<00:09,  7.95it/s]\u001b[A\n",
      " 62%|█████████████████████████▍               | 116/187 [00:14<00:08,  7.95it/s]\u001b[A\n",
      " 63%|█████████████████████████▋               | 117/187 [00:14<00:08,  7.96it/s]\u001b[A\n",
      " 63%|█████████████████████████▊               | 118/187 [00:14<00:08,  8.01it/s]\u001b[A\n",
      " 64%|██████████████████████████               | 119/187 [00:14<00:08,  8.12it/s]\u001b[A\n",
      " 64%|██████████████████████████▎              | 120/187 [00:14<00:08,  8.18it/s]\u001b[A\n",
      " 65%|██████████████████████████▌              | 121/187 [00:14<00:07,  8.30it/s]\u001b[A\n",
      " 65%|██████████████████████████▋              | 122/187 [00:14<00:07,  8.38it/s]\u001b[A\n",
      " 66%|██████████████████████████▉              | 123/187 [00:14<00:07,  8.37it/s]\u001b[A\n",
      " 66%|███████████████████████████▏             | 124/187 [00:15<00:07,  8.34it/s]\u001b[A\n",
      " 67%|███████████████████████████▍             | 125/187 [00:15<00:07,  8.35it/s]\u001b[A\n",
      " 67%|███████████████████████████▋             | 126/187 [00:15<00:07,  8.29it/s]\u001b[A\n",
      " 68%|███████████████████████████▊             | 127/187 [00:15<00:07,  8.35it/s]\u001b[A\n",
      " 68%|████████████████████████████             | 128/187 [00:15<00:07,  8.38it/s]\u001b[A\n",
      " 69%|████████████████████████████▎            | 129/187 [00:15<00:06,  8.34it/s]\u001b[A\n",
      " 70%|████████████████████████████▌            | 130/187 [00:15<00:06,  8.42it/s]\u001b[A\n",
      " 70%|████████████████████████████▋            | 131/187 [00:15<00:06,  8.49it/s]\u001b[A\n",
      " 71%|████████████████████████████▉            | 132/187 [00:15<00:06,  8.51it/s]\u001b[A\n",
      " 71%|█████████████████████████████▏           | 133/187 [00:16<00:06,  8.32it/s]\u001b[A\n",
      " 72%|█████████████████████████████▍           | 134/187 [00:16<00:06,  8.36it/s]\u001b[A\n",
      " 72%|█████████████████████████████▌           | 135/187 [00:16<00:06,  8.32it/s]\u001b[A\n",
      " 73%|█████████████████████████████▊           | 136/187 [00:16<00:06,  8.37it/s]\u001b[A\n",
      " 73%|██████████████████████████████           | 137/187 [00:16<00:06,  8.29it/s]\u001b[A\n",
      " 74%|██████████████████████████████▎          | 138/187 [00:16<00:05,  8.18it/s]\u001b[A\n",
      " 74%|██████████████████████████████▍          | 139/187 [00:16<00:05,  8.09it/s]\u001b[A\n",
      " 75%|██████████████████████████████▋          | 140/187 [00:16<00:05,  8.10it/s]\u001b[A\n",
      " 75%|██████████████████████████████▉          | 141/187 [00:17<00:05,  8.11it/s]\u001b[A\n",
      " 76%|███████████████████████████████▏         | 142/187 [00:17<00:05,  8.27it/s]\u001b[A\n",
      " 76%|███████████████████████████████▎         | 143/187 [00:17<00:05,  8.36it/s]\u001b[A\n",
      " 77%|███████████████████████████████▌         | 144/187 [00:17<00:05,  8.06it/s]\u001b[A\n",
      " 78%|███████████████████████████████▊         | 145/187 [00:17<00:05,  7.97it/s]\u001b[A\n",
      " 78%|████████████████████████████████         | 146/187 [00:17<00:05,  7.94it/s]\u001b[A\n",
      " 79%|████████████████████████████████▏        | 147/187 [00:17<00:05,  7.96it/s]\u001b[A\n",
      " 79%|████████████████████████████████▍        | 148/187 [00:17<00:04,  7.97it/s]\u001b[A\n",
      " 80%|████████████████████████████████▋        | 149/187 [00:18<00:04,  7.99it/s]\u001b[A\n",
      " 80%|████████████████████████████████▉        | 150/187 [00:18<00:04,  8.03it/s]\u001b[A\n",
      " 81%|█████████████████████████████████        | 151/187 [00:18<00:04,  8.05it/s]\u001b[A\n",
      " 81%|█████████████████████████████████▎       | 152/187 [00:18<00:04,  7.86it/s]\u001b[A\n",
      " 82%|█████████████████████████████████▌       | 153/187 [00:18<00:04,  7.82it/s]\u001b[A\n",
      " 82%|█████████████████████████████████▊       | 154/187 [00:18<00:04,  7.92it/s]\u001b[A\n",
      " 83%|█████████████████████████████████▉       | 155/187 [00:18<00:04,  7.85it/s]\u001b[A\n",
      " 83%|██████████████████████████████████▏      | 156/187 [00:18<00:03,  8.07it/s]\u001b[A\n",
      " 84%|██████████████████████████████████▍      | 157/187 [00:19<00:03,  8.25it/s]\u001b[A\n",
      " 84%|██████████████████████████████████▋      | 158/187 [00:19<00:03,  8.36it/s]\u001b[A\n",
      " 85%|██████████████████████████████████▊      | 159/187 [00:19<00:03,  8.39it/s]\u001b[A\n",
      " 86%|███████████████████████████████████      | 160/187 [00:19<00:03,  8.45it/s]\u001b[A\n",
      " 86%|███████████████████████████████████▎     | 161/187 [00:19<00:03,  8.46it/s]\u001b[A\n",
      " 87%|███████████████████████████████████▌     | 162/187 [00:19<00:02,  8.40it/s]\u001b[A\n",
      " 87%|███████████████████████████████████▋     | 163/187 [00:19<00:02,  8.32it/s]\u001b[A\n",
      " 88%|███████████████████████████████████▉     | 164/187 [00:19<00:02,  8.27it/s]\u001b[A\n",
      " 88%|████████████████████████████████████▏    | 165/187 [00:20<00:02,  8.25it/s]\u001b[A\n",
      " 89%|████████████████████████████████████▍    | 166/187 [00:20<00:02,  8.22it/s]\u001b[A\n",
      " 89%|████████████████████████████████████▌    | 167/187 [00:20<00:02,  8.23it/s]\u001b[A\n",
      " 90%|████████████████████████████████████▊    | 168/187 [00:20<00:02,  8.28it/s]\u001b[A\n",
      " 90%|█████████████████████████████████████    | 169/187 [00:20<00:02,  8.38it/s]\u001b[A\n",
      " 91%|█████████████████████████████████████▎   | 170/187 [00:20<00:02,  8.22it/s]\u001b[A\n",
      " 91%|█████████████████████████████████████▍   | 171/187 [00:20<00:01,  8.13it/s]\u001b[A\n",
      " 92%|█████████████████████████████████████▋   | 172/187 [00:20<00:01,  7.99it/s]\u001b[A\n",
      " 93%|█████████████████████████████████████▉   | 173/187 [00:21<00:01,  7.96it/s]\u001b[A\n",
      " 93%|██████████████████████████████████████▏  | 174/187 [00:21<00:01,  8.03it/s]\u001b[A\n",
      " 94%|██████████████████████████████████████▎  | 175/187 [00:21<00:01,  8.21it/s]\u001b[A\n",
      " 94%|██████████████████████████████████████▌  | 176/187 [00:21<00:01,  8.30it/s]\u001b[A\n",
      " 95%|██████████████████████████████████████▊  | 177/187 [00:21<00:01,  8.32it/s]\u001b[A\n",
      " 95%|███████████████████████████████████████  | 178/187 [00:21<00:01,  8.35it/s]\u001b[A\n",
      " 96%|███████████████████████████████████████▏ | 179/187 [00:21<00:00,  8.34it/s]\u001b[A\n",
      " 96%|███████████████████████████████████████▍ | 180/187 [00:21<00:00,  8.23it/s]\u001b[A\n",
      " 97%|███████████████████████████████████████▋ | 181/187 [00:21<00:00,  8.26it/s]\u001b[A\n",
      " 97%|███████████████████████████████████████▉ | 182/187 [00:22<00:00,  8.28it/s]\u001b[A\n",
      " 98%|████████████████████████████████████████ | 183/187 [00:22<00:00,  8.34it/s]\u001b[A\n",
      " 98%|████████████████████████████████████████▎| 184/187 [00:22<00:00,  8.18it/s]\u001b[A\n",
      " 99%|████████████████████████████████████████▌| 185/187 [00:22<00:00,  8.11it/s]\u001b[A\n",
      " 99%|████████████████████████████████████████▊| 186/187 [00:22<00:00,  8.04it/s]\u001b[A\n",
      "100%|█████████████████████████████████████████| 187/187 [00:22<00:00,  8.01it/s]\u001b[A\n",
      " 83%|████████████████████████████████▍      | 1000/1201 [08:34<47:32, 14.19s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 1000 0.000 0.000 100.00 100.00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|▏                                          | 1/187 [00:00<00:21,  8.57it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logging\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                  | 0/1201 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 1201 0.000 0.000 100.00 100.00\n",
      "running epoch 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|▏                                          | 1/187 [00:00<00:21,  8.62it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logging\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                  | 0/1201 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2 2402 0.000 0.000 100.00 100.00\n",
      "running epoch 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|▏                                          | 1/187 [00:00<00:21,  8.58it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logging\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3 3603 0.000 0.000 100.00 100.00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    }
   ],
   "source": [
    "# run\n",
    "best_score = 0\n",
    "for i in range(args.n_iter):\n",
    "    print(\"running epoch\", i)\n",
    "    run_epoch()\n",
    "    n_epochs += 1\n",
    "    log(save_dir, desc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-04T07:35:51.391469Z",
     "start_time": "2018-11-04T07:35:51.351500Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "def iter_predict(Xs, Ms):\n",
    "    logits = []\n",
    "    with torch.no_grad():\n",
    "        dh_model.eval()\n",
    "        for xmb, mmb in iter_data(Xs, Ms, n_batch=n_batch_train, truncate=False, verbose=True):\n",
    "            n = len(xmb)\n",
    "            XMB = torch.tensor(xmb, dtype=torch.long).to(device)\n",
    "#             MMB = torch.tensor(mmb).to(device)\n",
    "            lm_logits, _ = dh_model(XMB)\n",
    "#             print(lm_logits)\n",
    "#             return lm_logits.to(\"cpu\").numpy()\n",
    "            logits.append(lm_logits.to(\"cpu\").numpy())\n",
    "#     logits = np.concatenate(logits, 0)\n",
    "    logits = np.stack(logits, 0)\n",
    "    return logits\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-04T07:05:57.352254Z",
     "start_time": "2018-11-04T07:05:57.309677Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-04T07:36:02.860870Z",
     "start_time": "2018-11-04T07:36:00.685471Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(5, 1392, 40830)"
      ]
     },
     "execution_count": 214,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lm_logits = iter_predict(teX[:10], teM[:10])\n",
    "lm_logits.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-04T07:48:49.394904Z",
     "start_time": "2018-11-04T07:48:49.352655Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-04T07:48:39.761333Z",
     "start_time": "2018-11-04T07:48:39.720953Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-04T07:48:28.926154Z",
     "start_time": "2018-11-04T07:48:28.886384Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(40478, 40479, 40480)"
      ]
     },
     "execution_count": 233,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoder['_start_'], encoder['_delimiter_'], clf_token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-04T07:52:11.774586Z",
     "start_time": "2018-11-04T07:52:11.728445Z"
    }
   },
   "outputs": [],
   "source": [
    "convert = [    \n",
    "    ['</w><unk>', '<unk>'],\n",
    "    ['.<unk>', '<unk>'],\n",
    "    ['\"<unk>', '<unk>'],\n",
    "    ['<unk></w>', '<unk>'],\n",
    "    ['<unk>.', '<unk>'],\n",
    "    ['<unk>\"', '<unk>'],\n",
    "    ['<unk>', ''],\n",
    "    ['</w>,', ','],\n",
    "    [\"</w>'\", \"'\"],\n",
    "    ['</w>.', '.'],\n",
    "    ['</w>', ' '],\n",
    "    ['\"</w>', ''],\n",
    "    ['_delimiter_', '\\n'],\n",
    "#     ['_classify_', '\\n'],\n",
    "    ['_start_', '\\n']\n",
    "    \n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-04T07:52:27.709221Z",
     "start_time": "2018-11-04T07:52:11.977263Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\"., a same, a his silk he with evcast the trees forest he the h and to he is the moral's into way.. \n",
      "1 _classify_1 \" \" ,;, ..,. ., .. . .,. ,,,,,,,,,, ., a same, a his blue she with same lengthened the chapel, he the h, to he, the man's into the.. \n",
      ". _classify_. 2 19.. ., ., .. ;. .  . , . .   ,,,\n",
      ",;,,,... \n",
      "1 _classify_1 _classify__classify__,,,,a... \n",
      ". _classify_\n",
      "\n",
      "\" \n",
      " \n",
      "\n",
      "\" object and is _ the emerson the _, which has us fuller resemblance impression of the love of is has envy tolerance have caused about the race race, is no yet therto been written described. elaborated. to the original. it has to convey an more description of the the has existed and decent thinminded people beings have done offer in. notions about prejudices. order with the prejudices gnance. but see here poem of the very who lost so \" and his young desire strong man to the weak, a - bitter, selfish, and acious, a mother ments of innocent children and his of his children ; the was a and cold, he did him but felt, were ; his children. the floor. \n",
      "was with and the and helen daughter of becomes left, she children are suffer at the father's death. and cling she is is not bear feel that. be a loss. \n",
      "1 poet poet's a a a and _classify_1 .  . .  . ;..  . , . ...     . ;..,  ,,.,,  \" patient book, _ the's byron _, was is us fuller resemblance idea of the relationship of has has prejudice tolerance have brought about the young race, was a been therto been a published. even. to the authors. it is to explain a general description of the the has matters and true principles minded people nature feel done offer.. notions, prejudices. literature with the prejudices gnancies. the have here poem of the young who had a loving and his young opposition and husband to the weak, a - cruel, selfish, and acious, a son turers of children children and children of his children ; the just a, sickly ; he met him and saw, had, the children. the stairs ; \n",
      "was and he is and helen mother of the left, she child are suffer in seeing father's death. and they their is feels not bear feel the. be a pain. \n",
      "1 _classify_one........ . \n",
      "... ;. _classify_...    .. .  \n",
      "...     ,,, . ,.   object was 90. a year of the death trial marriage., the the nineteenth of january, 20, a court regent of regent by the father as declare his was a his charlotte, wales, the it was was the have for the court beginning to her the slightest sponial of the monarch which that he the marriage meeting he london louis he park he he he young declared sent before the, and scarcely her her william ford sbury, \" do up a glass of port, \" am not want well. \" \n",
      "1 malmesbury, him he glass of brandy would fix be sufficient to and which the sultan answered chivalof the throne, and that \" ceremony word, his mistress, _classify_1 _classify_,,,.. . . ;.,... \n",
      " . ,,,,,,,.,,. iiian penis was 98, a year of the discovery revolution marriage., the this twenty of january, 20 the a court regent of regent by his friends as take his was a his diana, wales, prince far was was the have for the court beginning of the the smallest sponial of the court. that he the marriage meeting he 18louis he park he the he prince was just before him, and proposed her her howard msbury, \" you up out cup of wine, \" am not care so. \n",
      "\n",
      "1 _classify_2 19 \n",
      "\n",
      ",  ,,,,,:\n",
      "\n",
      ". 18first stevenson to literary he his without to society, he was the his seventeenth year by of his life, when of the period of his the english sus _, was to deeper in the for place for the own. the productions. he thinking a for he were no foundation significance. the he was iciency of genan greatest of real facts facts in the life age. the he appear scholars religious observers can aid. in ideas of represent possess are, essential most and prejudices the personality. the personality, in the his ideas he he has back to the period period of his early, \n",
      "1 were the -, ages in the, monstrous human, and alistic, in and real person being can be in of them. and they individual that they they is is this is ancients reader can as the subject and of the story -- is of by despised. the. _classify_1, ........ \", \n",
      ",... .. ..........  ,  .. .., . . . ; ,   ,,, ;the the novel stevenson to bestiand scott without to the, he was in a latter year by of his life, the of _ end of the the first sus _, was to one in the for space for the own. the productions. he content a for as were no foundation foundation. he he is iciency, gena great of any ideals facts in his life age. which he form scholars literary writers can show. he most of represent possess are so in motive and and and impressions, shelley character. they shelley reideal, he has back to the beginning period, his early, \n",
      "1 _classify_3 22 \n",
      " ., .  ...., .  .,.  ,. :.  \n",
      " .  ;. .  it i were be any need, if demons, no earth, no which end,, nothing paracworld unvoid meaningless like nothingness meaningless, unmerciful led nothingness, then there creation were die be created eden's singu, my gospel, his ear, his blessing, his me in as last, the of the existence,, -- there all if in matter, or a than a the shape of i me, the, a my the,, dust, a should not to he not his and his arms arms, i carry me lips on me, as tell me from, and, down into -- everything there not the in to potent _, earth, to was at, \n",
      "1 when he, not die presence exist on heaven the i ? in is, him : all,. soul, of he and and, and ! _classify_1 _classify_ .   ...... _  _. ..   ,. ., .,....,.  ....,., . . . ,.,,..  i the is be any more, \" power, no earth, no which end,, no paracworld open void endless like void empty, dreamless merciful led space, i there the were are be equal own's,, my spirit, his sword, his blessing, his me with making universe surrounding the of all life world, if all the in in child in than a than a when presence of i me, the, the my the,, dust, a was appear to if be his up his arms winds, i kiss his lips on me, i kiss me from into and, down, \n",
      "i not not so ? to potent _, the ? and not, in \n",
      "1 _classify_. 22 _classify_.  ..,..,.. ..,, ;,,,\n",
      "\n",
      ". was who he work were him, was short work for a moment, turned his his ring's portion, he, not the similar opinion from he old anic he the day actiwas a his book confessions pan _ great _ was not tive and character with the's _ ary eloqu. the they. his english. but the's a attack at crowd dread fled the and to flee over attack. the feet. \n",
      "1 were him feet and they was feel avoid his feet ; and they was are no from he ton ne has shown, a numerous and. foot of on too by _classify_1 \",__classify_. .. ...  ,,,.,,,the, who speaking name were him, was short work and a moment to looked his his ring's head. he, not a opinion opinion from he old anic was the poet actiwas no the book _ pan _ great _ was not tive. disguise with the's _ ary and. the they. the _. the he's a attack at women, which the rose to take over attack. his feet. \n",
      "1 _classify_2 23.. \n",
      ".. .  ,  .,,,the was born born of action acuand and his it in well by he he did in a a, but in or small. but a. he was a first antiof the, he in was the the characteristics of he has to he moore was into of the his intellect of genius. he was built the lives poets of poets poets. history century country. and that has no the power century of this century literary.. poem. them own life oraries. \n",
      "the was a as dickens of been been,, the genius in word. and had none he the gifted stic. the, sceptiwere not have any poetry have compared absent ated by affecting tching causes.. the same. _classify_1 \" \" ',.., . _classify_. ..,...........,  .... . . . ..  .,.  \n",
      " .. ., .     ,'s a pioneer of action acu, and his great in well by he he wrote in a just, but in or mediocre. but a. his was the first master of the, he he was it the advantages of he possesses him and he had into of the his genius the the. he had in the very generation of poets poets. history generation english. and he has also the power century ; this century literary.. empire. them own life oraries. \n",
      "1 _classify_. 23 26  ,,..,. , . ,:,..,,.,  : .,    \n",
      "\n",
      "., in satisfied of the, his sm, said a in the own and he was his empire beyond it was the whole. he he did the in without his, opposed whole, ? supreme sin in his character ? a which rate a the poetry of by his period volume of his work - life, he defect was like much of poetic the, love - was the since in iled in the - indulgence. in poet of self and a the person intellect was the most, lacking him a denied him by \n",
      "1 his the masterpiece poem in a true he had upon the first of and was was a than a to make him transition material aware him a extraordinary. _classify_1 \" _classify_...  .. ;..,...... ......,. ... .. .  : ,,,.. ,....... ,,.,,:,. -,. \n",
      ".. . \"'s who healthy of the, the sm, made a in the work, and was his society and it was every whole. he he was his in without shelley when opposed whole, ? thousand sin ? his character ? a which rate an his poetic of by his period three of his life brilliant life, he defect, now bold of self the, the - was so since in iled in love - indulgence. he poet of self and a the person intellect, literature purest was replaced him a absent him. \n",
      "1 _classify_2 19 \"...... .., \".... .... \n",
      ".. ,,. .,,,... ;,,,,.,,    ,, in by of be seen of the's works in though that most of his youth love from bermuda icorn to the ith um. the his voyage death and paris he lost, of the weather journey of sailing the friends wife, the for lost for and of the sad that the lost deserted suspected sable body of in story ilpoet, that ship of nailed to, be carried, the's ship was then to the pyre ; the's his lney, the cian creroman rites ance. the not the with the grief. the land, who, and, and other were as to in the scene, \n",
      "1 sacrifice before sunny, the air beautiful magical. the sun, and the of the sun ëines of, _classify_1 ; .  . .,,,. ,.  . ; .  , the by of be seen of the's life in his a most of his youth journey from ireland icorn to the oyum. and his adventures appearance which ireland he lost, of the loss voyage spent in the family shipin the for island for of of the terrible that his treasure mythical recognisable remains of the tale ilpoet in that witness of addressed to, be carried, the's boat was then to the pyre, a, his acle ney in the cian precision roman rites ance ; the so the with the epi. the fort was who, and, and other were were consumed into the pyre, \n",
      "1 _classify_2 2 \n",
      ".....   , \n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "index 5 is out of bounds for axis 0 with size 5",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-244-4697685388d2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mtemperature\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.5\u001b[0m \u001b[0;31m# 1 is quite random, 0 is the most likely letter every time\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mbatch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprobs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0mprobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnp_softmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlm_logits\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtemperature\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# softmax with temperature\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mdist\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdistributions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mMultinomial\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# make distribution\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: index 5 is out of bounds for axis 0 with size 5"
     ]
    }
   ],
   "source": [
    "decoder = {v:k for k,v in text_encoder.encoder.items()}\n",
    "temperature = 0.5 # 1 is quite random, 0 is the most likely letter every time\n",
    "for batch in range(probs.shape[0]):\n",
    "    probs=np_softmax(lm_logits[batch], t=temperature) # softmax with temperature\n",
    "\n",
    "    dist = torch.distributions.Multinomial(probs=torch.from_numpy(probs)) # make distribution\n",
    "    y_encoded = dist.sample().argmax(-1).numpy() # sample\n",
    "    y_text = [decoder.get(i, \"<unk:{}>\".format(i)) for i in y_encoded] # decode\n",
    "    y_string = '\\n'+''.join(y_text) # join into text\n",
    "\n",
    "    # clean up tokens\n",
    "    y_string_raw = str(y_string)\n",
    "    for a, b in convert:\n",
    "        y_string = y_string.replace(a, b)\n",
    "\n",
    "    print(y_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "jupyter3",
   "language": "python",
   "name": "jupyter3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  },
  "toc": {
   "colors": {
    "hover_highlight": "#DAA520",
    "navigate_num": "#000000",
    "navigate_text": "#333333",
    "running_highlight": "#FF0000",
    "selected_highlight": "#FFD700",
    "sidebar_border": "#EEEEEE",
    "wrapper_background": "#FFFFFF"
   },
   "moveMenuLeft": true,
   "nav_menu": {
    "height": "171px",
    "width": "251px"
   },
   "navigate_menu": true,
   "number_sections": true,
   "sideBar": true,
   "threshold": 4,
   "toc_cell": false,
   "toc_position": {
    "height": "553px",
    "left": "0px",
    "right": "1191px",
    "top": "149px",
    "width": "185px"
   },
   "toc_section_display": "block",
   "toc_window_display": true,
   "widenNotebook": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
